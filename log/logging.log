
2017-06-01 08:26:29 --- Iteration: 1 --- Accurancy: 0.0393526212623 --- Loss: 6.6928047604

++++++++++++++++++++++++++++++++++++++++++++++++++

2017-06-01 08:26:32 --- Iteration: 1 --- Accurancy: 0.0733594041732 --- Loss: 6.68119478226

++++++++++++++++++++++++++++++++++++++++++++++++++

2017-06-01 08:26:34 --- Iteration: 1 --- Accurancy: 0.0659784442849 --- Loss: 6.63827848434

++++++++++++++++++++++++++++++++++++++++++++++++++

2017-06-01 08:26:37 --- Iteration: 2 --- Accurancy: 0.0547598381009 --- Loss: 6.35909981198

++++++++++++++++++++++++++++++++++++++++++++++++++

2017-06-01 08:26:39 --- Iteration: 2 --- Accurancy: 0.0477595134742 --- Loss: 5.99519930946

++++++++++++++++++++++++++++++++++++++++++++++++++

2017-06-01 08:26:41 --- Iteration: 2 --- Accurancy: 0.0533013405899 --- Loss: 5.87163930469

++++++++++++++++++++++++++++++++++++++++++++++++++

2017-06-01 08:26:43 --- Iteration: 3 --- Accurancy: 0.0605216096673 --- Loss: 5.70354837841

++++++++++++++++++++++++++++++++++++++++++++++++++

2017-06-01 08:26:46 --- Iteration: 3 --- Accurancy: 0.0553502374225 --- Loss: 5.61442899704

++++++++++++++++++++++++++++++++++++++++++++++++++

2017-06-01 08:26:48 --- Iteration: 3 --- Accurancy: 0.0901429984305 --- Loss: 5.61822435591

++++++++++++++++++++++++++++++++++++++++++++++++++

2017-06-01 08:26:50 --- Iteration: 4 --- Accurancy: 0.0560427473651 --- Loss: 5.61230617099

++++++++++++++++++++++++++++++++++++++++++++++++++

2017-06-01 08:26:53 --- Iteration: 4 --- Accurancy: 0.0494025204745 --- Loss: 5.56038517422

++++++++++++++++++++++++++++++++++++++++++++++++++

2017-06-01 08:26:55 --- Iteration: 4 --- Accurancy: 0.0634498351978 --- Loss: 5.53159777323

++++++++++++++++++++++++++++++++++++++++++++++++++

2017-06-01 08:26:57 --- Iteration: 5 --- Accurancy: 0.066427482499 --- Loss: 5.56191454993

++++++++++++++++++++++++++++++++++++++++++++++++++

2017-06-01 08:27:00 --- Iteration: 5 --- Accurancy: 0.0850666711728 --- Loss: 5.49307918549

++++++++++++++++++++++++++++++++++++++++++++++++++

2017-06-01 08:27:02 --- Iteration: 5 --- Accurancy: 0.0976014037927 --- Loss: 5.43286991119

++++++++++++++++++++++++++++++++++++++++++++++++++

2017-06-01 08:27:04 --- Iteration: 6 --- Accurancy: 0.0604621441 --- Loss: 5.51479985979

++++++++++++++++++++++++++++++++++++++++++++++++++

2017-06-01 08:27:07 --- Iteration: 6 --- Accurancy: 0.0621152164208 --- Loss: 5.43442026774

++++++++++++++++++++++++++++++++++++++++++++++++++

2017-06-01 08:27:09 --- Iteration: 6 --- Accurancy: 0.0801834861437 --- Loss: 5.395503415

++++++++++++++++++++++++++++++++++++++++++++++++++

2017-06-01 08:27:11 --- Iteration: 7 --- Accurancy: 0.0920268421372 --- Loss: 5.44734202491

++++++++++++++++++++++++++++++++++++++++++++++++++

2017-06-01 08:27:14 --- Iteration: 7 --- Accurancy: 0.0874627298779 --- Loss: 5.37094571855

++++++++++++++++++++++++++++++++++++++++++++++++++

2017-06-01 08:27:16 --- Iteration: 7 --- Accurancy: 0.0807602529724 --- Loss: 5.32116137611

++++++++++++++++++++++++++++++++++++++++++++++++++

2017-06-01 08:27:18 --- Iteration: 8 --- Accurancy: 0.0812675911519 --- Loss: 5.38479985131

++++++++++++++++++++++++++++++++++++++++++++++++++

2017-06-01 08:27:20 --- Iteration: 8 --- Accurancy: 0.101065397263 --- Loss: 5.30316787296

++++++++++++++++++++++++++++++++++++++++++++++++++

2017-06-01 08:27:23 --- Iteration: 8 --- Accurancy: 0.114460625582 --- Loss: 5.26070859697

++++++++++++++++++++++++++++++++++++++++++++++++++

2017-06-01 08:27:25 --- Iteration: 9 --- Accurancy: 0.11999124123 --- Loss: 5.31195428636

++++++++++++++++++++++++++++++++++++++++++++++++++

2017-06-01 08:27:27 --- Iteration: 9 --- Accurancy: 0.113029018044 --- Loss: 5.21167633269

++++++++++++++++++++++++++++++++++++++++++++++++++

2017-06-01 08:27:30 --- Iteration: 9 --- Accurancy: 0.119636441271 --- Loss: 5.1666785876

++++++++++++++++++++++++++++++++++++++++++++++++++

2017-06-01 09:56:07 --- Iteration: 1 --- Accurancy: 0.0317688344253 --- Loss: 6.6929842631

++++++++++++++++++++++++++++++++++++++++++++++++++

2017-06-01 09:56:10 --- Iteration: 1 --- Accurancy: 0.100574266579 --- Loss: 6.68389172024

++++++++++++++++++++++++++++++++++++++++++++++++++

2017-06-01 09:56:12 --- Iteration: 1 --- Accurancy: 0.0856160066194 --- Loss: 6.65741443634

++++++++++++++++++++++++++++++++++++++++++++++++++

2017-06-01 09:56:41 --- Iteration: 1 --- Accurancy: 0.0360242749254 --- Loss: 6.69300317764

++++++++++++++++++++++++++++++++++++++++++++++++++

2017-06-01 09:56:43 --- Iteration: 1 --- Accurancy: 0.0514629930258 --- Loss: 6.68288305071

++++++++++++++++++++++++++++++++++++++++++++++++++

2017-06-01 09:56:46 --- Iteration: 1 --- Accurancy: 0.0549703637759 --- Loss: 6.65567037794

++++++++++++++++++++++++++++++++++++++++++++++++++

2017-06-01 11:25:55 --- Iteration: 1 --- Accurancy: 0.040816232976 --- Loss: 6.69321865506

++++++++++++++++++++++++++++++++++++++++++++++++++

2017-06-01 12:55:35 --- Iteration: 1 --- Accurancy: 0.00184842874296 --- Loss: 6.69588518143

++++++++++++++++++++++++++++++++++++++++++++++++++

2017-06-01 12:55:36 --- Iteration: 1 --- Accurancy: 0.00204498972744 --- Loss: 6.69395875931

++++++++++++++++++++++++++++++++++++++++++++++++++

2017-06-01 12:55:37 --- Iteration: 1 --- Accurancy: 0.0435663536191 --- Loss: 6.69177961349

++++++++++++++++++++++++++++++++++++++++++++++++++

2017-06-01 12:55:39 --- Iteration: 2 --- Accurancy: 0.0727449208498 --- Loss: 6.6880364418

++++++++++++++++++++++++++++++++++++++++++++++++++

2017-06-01 12:55:40 --- Iteration: 2 --- Accurancy: 0.0745015516877 --- Loss: 6.68531513214

++++++++++++++++++++++++++++++++++++++++++++++++++

2017-06-01 12:55:41 --- Iteration: 2 --- Accurancy: 0.0782608538866 --- Loss: 6.68229389191

++++++++++++++++++++++++++++++++++++++++++++++++++

2017-06-01 12:55:43 --- Iteration: 3 --- Accurancy: 0.0863239690661 --- Loss: 6.6771440506

++++++++++++++++++++++++++++++++++++++++++++++++++

2017-06-01 12:55:44 --- Iteration: 3 --- Accurancy: 0.0819490477443 --- Loss: 6.671189785

++++++++++++++++++++++++++++++++++++++++++++++++++

2017-06-01 12:55:45 --- Iteration: 3 --- Accurancy: 0.0680772960186 --- Loss: 6.66250801086

++++++++++++++++++++++++++++++++++++++++++++++++++

2017-06-01 12:55:46 --- Iteration: 4 --- Accurancy: 0.0648994892836 --- Loss: 6.65035200119

++++++++++++++++++++++++++++++++++++++++++++++++++

2017-06-01 14:23:13 --- Iteration: 1 --- Accurancy: 0.0301034169272 --- Loss: 6.69303970337

++++++++++++++++++++++++++++++++++++++++++++++++++

2017-06-01 14:23:15 --- Iteration: 1 --- Accurancy: 0.102275286615 --- Loss: 6.68188486099

++++++++++++++++++++++++++++++++++++++++++++++++++

2017-06-06 10:58:31 --- Iteration: 1 --- Accurancy: 0.0204263786872 --- Loss: 6.69444731213

++++++++++++++++++++++++++++++++++++++++++++++++++

2017-06-06 10:58:35 --- Iteration: 2 --- Accurancy: 0.0904094311378 --- Loss: 6.68443612863

++++++++++++++++++++++++++++++++++++++++++++++++++

2017-06-06 10:58:37 --- Iteration: 3 --- Accurancy: 0.0763982013361 --- Loss: 6.66965980719

++++++++++++++++++++++++++++++++++++++++++++++++++

2017-06-06 10:58:40 --- Iteration: 4 --- Accurancy: 0.0622328644902 --- Loss: 6.63357778259

++++++++++++++++++++++++++++++++++++++++++++++++++

2017-06-06 10:58:43 --- Iteration: 5 --- Accurancy: 0.0583338169073 --- Loss: 6.49377359933

++++++++++++++++++++++++++++++++++++++++++++++++++

2017-06-06 10:58:46 --- Iteration: 6 --- Accurancy: 0.0572874767101 --- Loss: 6.19768137332

++++++++++++++++++++++++++++++++++++++++++++++++++

2017-06-06 10:58:49 --- Iteration: 7 --- Accurancy: 0.0561504113112 --- Loss: 5.94927023578

++++++++++++++++++++++++++++++++++++++++++++++++++

2017-06-06 10:58:52 --- Iteration: 8 --- Accurancy: 0.0536816950813 --- Loss: 5.81268291915

++++++++++++++++++++++++++++++++++++++++++++++++++

2017-06-06 10:58:55 --- Iteration: 9 --- Accurancy: 0.0530339171061 --- Loss: 5.73536405184

++++++++++++++++++++++++++++++++++++++++++++++++++
